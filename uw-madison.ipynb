{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport gc\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom typing import Optional\nfrom glob import glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras\nfrom keras.models import load_model, save_model\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\n\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:43.402202Z","iopub.execute_input":"2022-07-05T16:12:43.402553Z","iopub.status.idle":"2022-07-05T16:12:43.412160Z","shell.execute_reply.started":"2022-07-05T16:12:43.402519Z","shell.execute_reply":"2022-07-05T16:12:43.411168Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nEPOCH = 10\nn_splits = 5\nfold_selected = 2\n\nTRAIN_ROOT_DIR = \"../input/uw-madison-gi-tract-image-segmentation/\"\nTEST_ROOT_DIR = \"../input/uw-madison-gi-tract-image-segmentation/test/\"","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:43.628039Z","iopub.execute_input":"2022-07-05T16:12:43.628307Z","iopub.status.idle":"2022-07-05T16:12:43.633660Z","shell.execute_reply.started":"2022-07-05T16:12:43.628283Z","shell.execute_reply":"2022-07-05T16:12:43.632560Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_df_original = pd.read_csv(TRAIN_ROOT_DIR + 'train.csv')\n\nprint(train_df_original.shape)\ntrain_df_original.head(30)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:43.784492Z","iopub.execute_input":"2022-07-05T16:12:43.785266Z","iopub.status.idle":"2022-07-05T16:12:44.055842Z","shell.execute_reply.started":"2022-07-05T16:12:43.785227Z","shell.execute_reply":"2022-07-05T16:12:44.054844Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(28, 12))\ntrain_df_original['class'].value_counts(normalize=True).plot.pie()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:44.057808Z","iopub.execute_input":"2022-07-05T16:12:44.058440Z","iopub.status.idle":"2022-07-05T16:12:44.211156Z","shell.execute_reply.started":"2022-07-05T16:12:44.058399Z","shell.execute_reply":"2022-07-05T16:12:44.210110Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(TRAIN_ROOT_DIR + 'sample_submission.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:45.252591Z","iopub.execute_input":"2022-07-05T16:12:45.252939Z","iopub.status.idle":"2022-07-05T16:12:45.268804Z","shell.execute_reply.started":"2022-07-05T16:12:45.252910Z","shell.execute_reply":"2022-07-05T16:12:45.267704Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"if len(test_df) == 0:\n    DEBUG=True\n    # test_df=train_df_original.iloc[:300, :]\n    test_df=pd.read_csv(TRAIN_ROOT_DIR + 'train.csv').iloc[:300, :]\n    test_df['segmentation'] = ''\n    test_df = test_df.rename(columns={'segmentation' : 'prediction'})\nelse:\n    DEBUG=False\n    \nsubmission = test_df.copy()\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:45.476926Z","iopub.execute_input":"2022-07-05T16:12:45.477221Z","iopub.status.idle":"2022-07-05T16:12:45.737678Z","shell.execute_reply.started":"2022-07-05T16:12:45.477196Z","shell.execute_reply":"2022-07-05T16:12:45.736722Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"train_df_original.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:45.739748Z","iopub.execute_input":"2022-07-05T16:12:45.740133Z","iopub.status.idle":"2022-07-05T16:12:45.750243Z","shell.execute_reply.started":"2022-07-05T16:12:45.740097Z","shell.execute_reply":"2022-07-05T16:12:45.749184Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"train_df_original.head()\ntrain_df_original.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:45.756123Z","iopub.execute_input":"2022-07-05T16:12:45.756604Z","iopub.status.idle":"2022-07-05T16:12:45.763848Z","shell.execute_reply.started":"2022-07-05T16:12:45.756568Z","shell.execute_reply":"2022-07-05T16:12:45.762903Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def df_preparation(df, subset='train', DEBUG=False) :\n    df['case'] = df['id'].apply(lambda x : int(x.split('_')[0].replace('case', '')))\n    df['day'] = df['id'].apply(lambda x : int(x.split('_')[1].replace('day', '')))\n    df['slice'] = df['id'].apply(lambda x : x.split('_')[3])\n    \n    if(subset == 'train') or (DEBUG) :\n        DIR = TRAIN_ROOT_DIR + \"train\"\n    else :\n        DIR = TEST_ROOT_DIR\n        \n    all_images = glob(os.path.join(DIR, \"**\", \"*.png\"), recursive=True)\n    print(\"all_images length \", len(all_images))\n    \n    x = all_images[0].rsplit(\"/\", 4)[0]\n    print(x)\n    path_partial_list = []\n    for i in range(0, df.shape[0]):\n        path_partial_list.append(\n            os.path.join(\n                x,\n                \"case\" + str(df[\"case\"].values[i]),\n                \"case\"\n                + str(df[\"case\"].values[i])\n                + \"_\"\n                + \"day\"\n                + str(df[\"day\"].values[i]),\n                \"scans\",\n                \"slice_\" + str(df[\"slice\"].values[i]),\n            )\n        )\n    df[\"path_partial\"] = path_partial_list\n    path_partial_list = []\n    for i in range(0, len(all_images)):\n        path_partial_list.append(str(all_images[i].rsplit(\"_\", 4)[0]))\n\n    tmp_df = pd.DataFrame()\n    tmp_df[\"path_partial\"] = path_partial_list\n    tmp_df[\"path\"] = all_images\n\n    df = df.merge(tmp_df, on=\"path_partial\").drop(columns=[\"path_partial\"])\n\n    df[\"width\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[1]))\n    df[\"height\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\", 4)[2]))\n\n    del x, path_partial_list, tmp_df\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:45.882940Z","iopub.execute_input":"2022-07-05T16:12:45.883864Z","iopub.status.idle":"2022-07-05T16:12:45.898645Z","shell.execute_reply.started":"2022-07-05T16:12:45.883816Z","shell.execute_reply":"2022-07-05T16:12:45.897539Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"train_df = df_preparation(train_df_original, subset='train')\ntrain_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:46.127651Z","iopub.execute_input":"2022-07-05T16:12:46.128417Z","iopub.status.idle":"2022-07-05T16:12:50.314688Z","shell.execute_reply.started":"2022-07-05T16:12:46.128372Z","shell.execute_reply":"2022-07-05T16:12:50.313599Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"print(train_df['path'][0])\nprint(train_df['path'][1])\nprint(train_df['path'][2])\nprint(train_df['path'][3])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:50.316963Z","iopub.execute_input":"2022-07-05T16:12:50.317326Z","iopub.status.idle":"2022-07-05T16:12:50.328348Z","shell.execute_reply.started":"2022-07-05T16:12:50.317289Z","shell.execute_reply":"2022-07-05T16:12:50.327416Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"test_df.head()\ntest_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:50.329960Z","iopub.execute_input":"2022-07-05T16:12:50.330462Z","iopub.status.idle":"2022-07-05T16:12:50.337036Z","shell.execute_reply.started":"2022-07-05T16:12:50.330426Z","shell.execute_reply":"2022-07-05T16:12:50.336070Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"test_df=df_preparation(test_df, subset=\"test\", DEBUG=True)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:50.340246Z","iopub.execute_input":"2022-07-05T16:12:50.340949Z","iopub.status.idle":"2022-07-05T16:12:51.111678Z","shell.execute_reply.started":"2022-07-05T16:12:50.340911Z","shell.execute_reply":"2022-07-05T16:12:51.110692Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"test_df['path'][0]","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:51.113309Z","iopub.execute_input":"2022-07-05T16:12:51.114001Z","iopub.status.idle":"2022-07-05T16:12:51.122426Z","shell.execute_reply.started":"2022-07-05T16:12:51.113962Z","shell.execute_reply":"2022-07-05T16:12:51.121496Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def df_rearrange_for_3_segmentation_classes(df, subset=\"train\"):\n    df_restructured = pd.DataFrame({\"id\": df[\"id\"][::3]})\n\n    if subset == \"train\":\n        df_restructured[\"large_bowel\"] = df[\"segmentation\"][::3].values\n        df_restructured[\"small_bowel\"] = df[\"segmentation\"][1::3].values\n        df_restructured[\"stomach\"] = df[\"segmentation\"][2::3].values\n\n    df_restructured[\"path\"] = df[\"path\"][::3].values\n    df_restructured[\"case\"] = df[\"case\"][::3].values\n    df_restructured[\"day\"] = df[\"day\"][::3].values\n    df_restructured[\"slice\"] = df[\"slice\"][::3].values\n    df_restructured[\"width\"] = df[\"width\"][::3].values\n    df_restructured[\"height\"] = df[\"height\"][::3].values\n\n    df_restructured = df_restructured.reset_index(drop=True)\n    df_restructured = df_restructured.fillna(\"\")\n    if subset == \"train\":\n        df_restructured[\"count\"] = np.sum(\n            df_restructured.iloc[:, 1:4] != \"\", axis=1\n        ).values\n\n    return df_restructured\n","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:51.124117Z","iopub.execute_input":"2022-07-05T16:12:51.124394Z","iopub.status.idle":"2022-07-05T16:12:51.137124Z","shell.execute_reply.started":"2022-07-05T16:12:51.124370Z","shell.execute_reply":"2022-07-05T16:12:51.135926Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"train_df_rearranged=df_rearrange_for_3_segmentation_classes(train_df, subset=\"train\")\ntrain_df_rearranged.head(100)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:51.138615Z","iopub.execute_input":"2022-07-05T16:12:51.139011Z","iopub.status.idle":"2022-07-05T16:12:51.217508Z","shell.execute_reply.started":"2022-07-05T16:12:51.138976Z","shell.execute_reply":"2022-07-05T16:12:51.216436Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"train_df_rearranged = train_df_rearranged[(train_df['case']!=7)|(train_df['day']!=0)].reset_index(drop=True)\n\ntrain_df_rearranged = train_df_rearranged[(train_df['case']!=81)|(train_df['day']!=30)].reset_index(drop=True)\n\ntrain_df_rearranged = train_df_rearranged[(train_df['case']!=138)|(train_df['day']!=00)].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:51.218649Z","iopub.execute_input":"2022-07-05T16:12:51.218923Z","iopub.status.idle":"2022-07-05T16:12:51.254720Z","shell.execute_reply.started":"2022-07-05T16:12:51.218899Z","shell.execute_reply":"2022-07-05T16:12:51.253815Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:51.256389Z","iopub.execute_input":"2022-07-05T16:12:51.257053Z","iopub.status.idle":"2022-07-05T16:12:51.592462Z","shell.execute_reply.started":"2022-07-05T16:12:51.257015Z","shell.execute_reply":"2022-07-05T16:12:51.591462Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"def plot_bar(df):\n    plt.figure(figsize=(12, 6))\n    bar = plt.bar([1, 2, 3], 100 * np.mean(df.iloc[:, 1:4] != \"\", axis=0))\n    plt.title(\"Percent Training Images with Mask\", fontsize=16)\n    plt.ylabel(\"Percent of Train images with mask\")\n    plt.xlabel(\"Class Types\")\n    # labels = [\"large bowel\", \"small bowel\", \"stomach\"]\n    labels = [\"large_bowel\", \"small_bowel\", \"stomach\"]\n\n    for rect, lbl in zip(bar, labels):\n        height = rect.get_height()\n        plt.text(\n            rect.get_x() + rect.get_width() / 3,\n            height,\n            lbl,\n            ha=\"center\",\n            va=\"bottom\",\n            fontsize=12,\n        )\n\n    plt.ylim((0, 50))\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:51.599110Z","iopub.execute_input":"2022-07-05T16:12:51.599405Z","iopub.status.idle":"2022-07-05T16:12:51.609221Z","shell.execute_reply.started":"2022-07-05T16:12:51.599380Z","shell.execute_reply":"2022-07-05T16:12:51.608098Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"plot_bar(train_df_rearranged)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:51.610884Z","iopub.execute_input":"2022-07-05T16:12:51.611261Z","iopub.status.idle":"2022-07-05T16:12:51.823693Z","shell.execute_reply.started":"2022-07-05T16:12:51.611226Z","shell.execute_reply":"2022-07-05T16:12:51.822788Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport cv2\n\nimport tensorflow as tf\n\n\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, batch_size=BATCH_SIZE, subset=\"train\", shuffle=False):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(df))\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    \"\"\" __getitem__ returns a batch of images and masks \"\"\"\n\n    def __getitem__(self, index):\n        X = np.empty((self.batch_size, 128, 128, 3))  # Makes a 4-D Tensor\n        y = np.empty((self.batch_size, 128, 128, 3))  # Makes a 4-D Tensor\n\n        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n\n        for i, img_path in enumerate(self.df[\"path\"].iloc[indexes]):\n            # print(\"df['path'].iloc[indexes].shape \", self.df['path'].iloc[indexes].shape) # (16,)\n            # in above 'i' is just the counter. i.e. starts from 0 and goes upto the max length of all the rows\n            w = self.df[\"width\"].iloc[\n                indexes[i]\n            ]  # selects the row number of indexes[i]\n            h = self.df[\"height\"].iloc[indexes[i]]\n            img = self._load_grayscaled_img(img_path)  # shape: (128,128,1)\n            # print('img shape after _load_grayscaled_img ', img.shape) #(128, 128, 1)\n            # Now update X[i,] to be this image.\n            X[\n                i,\n            ] = img  # broadcast to shape: (128,128,3)\n            # As we know, that arr[1,] is equivalent to arr[1, :]\n            # As NumPy will automatically insert trailing slices for you\n\n            # print('X after ', X.shape) # (16, 128, 128, 3)\n            # The slice notation in the above line means -\n            # Set me the (i+1)th Row of X to be this image\n\n            if self.subset == \"train\":\n                for k, j in enumerate([\"large_bowel\", \"small_bowel\", \"stomach\"]):\n                    # Now 'j' will take each value from the above list\n                    # e.g. self.df['large_bowel']\n                    # and in my train_df_rearranged each of the [\"large_bowel\",\"small_bowel\",\"stomach\"]\n                    # column names contain RLE formatted segmentation data.\n                    rles = self.df[j].iloc[indexes[i]]\n                    # so the above line will actually be something like => self.df['stomach'].iloc[indexes[20]]\n                    # giving me the RLE data for that row and column\n                    # mask = rle_decode(rles, shape=(h, w, 1))\n                    # if all my utils method is in separate file then uncomment below\n                    mask = rle_decode(rles, shape=(h, w, 1))\n                    mask = cv2.resize(mask, (128, 128))\n                    y[i, :, :, k] = mask\n        if self.subset == \"train\":\n            return X, y\n        else:\n            return X\n\n    def _load_grayscaled_img(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n        img_size = (128, 128)\n        img = cv2.resize(img, img_size)\n        img = img.astype(np.float32) / 255.0\n        img = np.expand_dims(img, axis=-1)\n        return img\n\n    \"\"\"cv2.IMREAD_ANYDEPTH => If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit. \"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:51.826213Z","iopub.execute_input":"2022-07-05T16:12:51.827023Z","iopub.status.idle":"2022-07-05T16:12:51.843846Z","shell.execute_reply.started":"2022-07-05T16:12:51.826984Z","shell.execute_reply":"2022-07-05T16:12:51.842879Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"def rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef rle_decode(mask_rle, shape, color=1):\n    s = mask_rle.split()\n    starts, length = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + length\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = color\n    return img.reshape(shape)\n\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n    return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + dice_loss(tf.cast(y_true, tf.float32), y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:29:56.586666Z","iopub.execute_input":"2022-07-05T17:29:56.587676Z","iopub.status.idle":"2022-07-05T17:29:56.602980Z","shell.execute_reply.started":"2022-07-05T17:29:56.587623Z","shell.execute_reply":"2022-07-05T17:29:56.601760Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"def plot_mask_with_color_patches(df, colors, labels):\n    list_indices_of_mask_random = list(\n        df[df[\"large_bowel\"] != \"\"].sample(BATCH_SIZE).index\n    )\n    list_indices_of_mask_random += list(\n        df[df[\"small_bowel\"] != \"\"].sample(BATCH_SIZE * 2).index\n    )\n    list_indices_of_mask_random += list(\n        df[df[\"stomach\"] != \"\"].sample(BATCH_SIZE * 3).index\n    )\n    # print('list_indices_of_mask_random ', list_indices_of_mask_random)\n    # It will be a list of indexes like [15176, 13709, 30423, ..., 12730]\n\n    batches_from_datagen = DataGenerator(\n        df[df.index.isin(list_indices_of_mask_random)], shuffle=True\n    )\n\n    num_rows = 6\n\n    fig = plt.figure(figsize=(10, 25))\n    gs = gridspec.GridSpec(nrows=num_rows, ncols=2)\n    patches = [\n        mpatches.Patch(color=colors[i], label=f\"{labels[i]}\")\n        for i in range(len(labels))\n    ]\n\n    cmap1 = mpl.colors.ListedColormap(colors[0])\n    cmap2 = mpl.colors.ListedColormap(colors[1])\n    cmap3 = mpl.colors.ListedColormap(colors[2])\n    \"\"\" The `matplotlib.colors.ListedColormap` class is used to create colarmap objects from a list of colors.\n    The class belongs to the `matplotlib.colors` module. This module is used for converting color or numbers arguments to RGBA or RGB and for mapping numbers to colors or color specification conversion in a 1-D array of colors also known as colormap.\n    This can be useful for directly indexing into colormap and it can also be used to create special colormaps for normal mapping. \"\"\"\n\n    for i in range(num_rows):\n        images, mask = batches_from_datagen[i]\n        # print('images.shape ', images.shape) # (16, 128, 128, 3)\n        # print('mask.shape ', mask.shape) # (16, 128, 128, 3)\n        \"\"\"\n        For each ID, we are going to create an image of shape [img height, img width, 3], where 3 (number of channels) are the 3 layers for each class:\n        * the first layer: large bowel\n        * the second layer: small bowel\n        * the third layer: stomach\n        \"\"\"\n        sample_img = images[0, :, :, 0]  # After this the shapes will be (128, 128)\n        mask1 = mask[0, :, :, 0]  # After this the shapes will be (128, 128)\n        mask2 = mask[0, :, :, 1]  # After this the shapes will be (128, 128)\n        mask3 = mask[0, :, :, 2]  # After this the shapes will be (128, 128)\n\n        ax0 = fig.add_subplot(gs[i, 0])  # i here is the row-counter which is 6\n        im = ax0.imshow(sample_img, cmap=\"bone\")\n\n        ax1 = fig.add_subplot(gs[i, 1])\n        if i == 0:\n            ax0.set_title(\"Image\", fontsize=15, weight=\"bold\", y=1.02)\n            ax1.set_title(\"Mask\", fontsize=15, weight=\"bold\", y=1.02)\n            plt.legend(\n                handles=patches,\n                bbox_to_anchor=(1.1, 0.65),\n                loc=2,\n                borderaxespad=0.4,\n                fontsize=14,\n                title=\"Mask Labels\",\n                title_fontsize=14,\n                edgecolor=\"black\",\n                facecolor=\"#c5c6c7\",\n            )\n\n        # print('mask1 ', mask1.shape) # (128, 128)\n        # print('mask2 ', mask2.shape) # (128, 128)\n        # print('mask3 ', mask3.shape) # (128, 128)\n        # print('np.ma.masked_where(mask1== False,  mask1) ', np.ma.masked_where(mask1== True,  mask1))\n        l0 = ax1.imshow(sample_img, cmap=\"bone\")\n        l1 = ax1.imshow(np.ma.masked_where(mask1 == False, mask1), cmap=cmap1, alpha=1)\n        l2 = ax1.imshow(np.ma.masked_where(mask2 == False, mask2), cmap=cmap2, alpha=1)\n        l3 = ax1.imshow(np.ma.masked_where(mask3 == False, mask3), cmap=cmap3, alpha=1)\n        # l1 = ax1.imshow(np.ma.masked_where(mask1== 0,  mask1),cmap=cmap1, alpha=1)\n        # l2 = ax1.imshow(np.ma.masked_where(mask2== 0,  mask2),cmap=cmap2, alpha=1)\n        # l3 = ax1.imshow(np.ma.masked_where(mask3== 0,  mask3),cmap=cmap3, alpha=1)\n        _ = [ax.set_axis_off() for ax in [ax0, ax1]]\n\n        colors = [im.cmap(im.norm(1)) for im in [l1, l2, l3]]","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:29:57.546432Z","iopub.execute_input":"2022-07-05T17:29:57.546883Z","iopub.status.idle":"2022-07-05T17:29:57.578915Z","shell.execute_reply.started":"2022-07-05T17:29:57.546841Z","shell.execute_reply":"2022-07-05T17:29:57.577837Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"colors = ['blue', 'green', 'red']\nlabels = ['large_bowel', 'small_bowel', 'stomach']\nplot_mask_with_color_patches(train_df_rearranged, colors, labels)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:51.887139Z","iopub.execute_input":"2022-07-05T16:12:51.889199Z","iopub.status.idle":"2022-07-05T16:12:54.045558Z","shell.execute_reply.started":"2022-07-05T16:12:51.888981Z","shell.execute_reply":"2022-07-05T16:12:54.044342Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\nfor fold, (_, val_idx) in enumerate(\n    skf.split(\n        X=train_df_rearranged,\n        y=train_df_rearranged[\"count\"],\n        groups=train_df_rearranged[\"case\"],\n    ),\n    1,\n):\n\n    train_df_rearranged.loc[val_idx, 'fold'] = fold\n    \ntrain_df_rearranged[\"fold\"] = train_df_rearranged[\"fold\"].astype(np.uint8)\n\ntrain_ids = train_df_rearranged[train_df_rearranged[\"fold\"] != fold_selected].index\nvalid_ids = train_df_rearranged[train_df_rearranged[\"fold\"] == fold_selected].index\n\nX_train = train_df_rearranged[train_df_rearranged.index.isin(train_ids)]\nX_valid = train_df_rearranged[train_df_rearranged.index.isin(valid_ids)]\n\ntrain_df_rearranged.groupby(\"fold\").size()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:54.047385Z","iopub.execute_input":"2022-07-05T16:12:54.047828Z","iopub.status.idle":"2022-07-05T16:12:54.218720Z","shell.execute_reply.started":"2022-07-05T16:12:54.047793Z","shell.execute_reply":"2022-07-05T16:12:54.217707Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"train_df_rearranged.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:54.220085Z","iopub.execute_input":"2022-07-05T16:12:54.220441Z","iopub.status.idle":"2022-07-05T16:12:54.235177Z","shell.execute_reply.started":"2022-07-05T16:12:54.220407Z","shell.execute_reply":"2022-07-05T16:12:54.234075Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"train_df_rearranged.groupby(['fold', 'count'])['id'].count()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:54.237006Z","iopub.execute_input":"2022-07-05T16:12:54.237714Z","iopub.status.idle":"2022-07-05T16:12:54.255521Z","shell.execute_reply.started":"2022-07-05T16:12:54.237675Z","shell.execute_reply":"2022-07-05T16:12:54.254446Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"experiment = False\nif experiment:\n    X_train = X_train[X_train.case.isin(X_train.case.unique()[:5])]\n    X_valid = X_valid[X_valid.case.isin(X_valid.case.unique()[:2])]\n    \nprint(X_train.shape)\nprint(X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:54.257077Z","iopub.execute_input":"2022-07-05T16:12:54.257437Z","iopub.status.idle":"2022-07-05T16:12:54.263821Z","shell.execute_reply.started":"2022-07-05T16:12:54.257405Z","shell.execute_reply":"2022-07-05T16:12:54.262704Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:54.268291Z","iopub.execute_input":"2022-07-05T16:12:54.269174Z","iopub.status.idle":"2022-07-05T16:12:54.290621Z","shell.execute_reply.started":"2022-07-05T16:12:54.269133Z","shell.execute_reply":"2022-07-05T16:12:54.289796Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"X_valid","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:54.293355Z","iopub.execute_input":"2022-07-05T16:12:54.293603Z","iopub.status.idle":"2022-07-05T16:12:54.315013Z","shell.execute_reply.started":"2022-07-05T16:12:54.293581Z","shell.execute_reply":"2022-07-05T16:12:54.314169Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"train_generator = DataGenerator(X_train, shuffle = True)\nval_generator = DataGenerator(X_valid)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:54.316355Z","iopub.execute_input":"2022-07-05T16:12:54.316797Z","iopub.status.idle":"2022-07-05T16:12:54.322935Z","shell.execute_reply.started":"2022-07-05T16:12:54.316745Z","shell.execute_reply":"2022-07-05T16:12:54.321957Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"train_generator","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:12:54.324552Z","iopub.execute_input":"2022-07-05T16:12:54.325350Z","iopub.status.idle":"2022-07-05T16:12:54.334428Z","shell.execute_reply.started":"2022-07-05T16:12:54.325310Z","shell.execute_reply":"2022-07-05T16:12:54.333511Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":" pip install segmentation-models","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:13:08.699859Z","iopub.execute_input":"2022-07-05T16:13:08.700391Z","iopub.status.idle":"2022-07-05T16:13:18.033979Z","shell.execute_reply.started":"2022-07-05T16:13:08.700354Z","shell.execute_reply":"2022-07-05T16:13:18.032646Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"! pip install git+https://github.com/qubvel/segmentation_models","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:13:18.036057Z","iopub.execute_input":"2022-07-05T16:13:18.036359Z","iopub.status.idle":"2022-07-05T16:13:30.061377Z","shell.execute_reply.started":"2022-07-05T16:13:18.036331Z","shell.execute_reply":"2022-07-05T16:13:30.060192Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')\nsm.framework()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:13:30.064668Z","iopub.execute_input":"2022-07-05T16:13:30.065101Z","iopub.status.idle":"2022-07-05T16:13:30.072211Z","shell.execute_reply.started":"2022-07-05T16:13:30.065057Z","shell.execute_reply":"2022-07-05T16:13:30.071252Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models.utils import set_trainable\n\nmodel = Unet('inceptionresnetv2', input_shape=(128, 128, 3), classes=3, activation='sigmoid', encoder_weights = 'imagenet' )\nmodel.compile(optimizer = 'adam', loss=bce_dice_loss, metrics=[dice_coef, iou_coef])","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:13:30.075138Z","iopub.execute_input":"2022-07-05T16:13:30.076019Z","iopub.status.idle":"2022-07-05T16:13:35.113417Z","shell.execute_reply.started":"2022-07-05T16:13:30.075970Z","shell.execute_reply":"2022-07-05T16:13:35.112434Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    'UNET_model',\n    monitor = 'val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode = 'auto'\n)\n\nearly_stopping = EarlyStopping(\n    patience = 5,\n    min_delta = 0.0001,\n    restore_best_weights= True\n)\n\nlr_plateau = keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.1,\n    patience=5,\n    verbose=0,\n    min_delta=0.0001,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:13:35.114938Z","iopub.execute_input":"2022-07-05T16:13:35.115285Z","iopub.status.idle":"2022-07-05T16:13:35.122565Z","shell.execute_reply.started":"2022-07-05T16:13:35.115250Z","shell.execute_reply":"2022-07-05T16:13:35.121505Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint, early_stopping],\n    use_multiprocessing=False,\n    workers=4,\n    epochs=EPOCH\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T16:13:35.124175Z","iopub.execute_input":"2022-07-05T16:13:35.124658Z","iopub.status.idle":"2022-07-05T17:23:14.561840Z","shell.execute_reply.started":"2022-07-05T16:13:35.124621Z","shell.execute_reply":"2022-07-05T17:23:14.559925Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.to_csv('history_df')","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:23:16.810429Z","iopub.execute_input":"2022-07-05T17:23:16.810802Z","iopub.status.idle":"2022-07-05T17:23:16.824424Z","shell.execute_reply.started":"2022-07-05T17:23:16.810752Z","shell.execute_reply":"2022-07-05T17:23:16.823156Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nplt.subplot(1, 3, 1)\nplt.plot(range(history.epoch[-1] + 1), history.history['loss'], label='Train Loss' )\nplt.plot(range(history.epoch[-1] + 1), history.history['val_loss'], label='Validation Loss' )\nplt.title('Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Losses')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(range(history.epoch[-1] + 1), history.history['dice_coef'], label='Train Dice Coeff' )\nplt.plot(range(history.epoch[-1] + 1), history.history['val_dice_coef'], label='Validation Dice Coef' )\nplt.title('Dice Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Dice Coef')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(range(history.epoch[-1] + 1), history.history['iou_coef'], label='Train IoU Coeff' )\nplt.plot(range(history.epoch[-1] + 1), history.history['val_iou_coef'], label='Validation IoU Coef' )\nplt.title('IoU Loss')\nplt.xlabel('Epochs')\nplt.ylabel('IoU Coef')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:23:16.825804Z","iopub.execute_input":"2022-07-05T17:23:16.826447Z","iopub.status.idle":"2022-07-05T17:23:17.284598Z","shell.execute_reply.started":"2022-07-05T17:23:16.826408Z","shell.execute_reply":"2022-07-05T17:23:17.283678Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"pred_batches = DataGenerator(X_valid.iloc[200:208, :], batch_size=1, subset='train', shuffle=True)\npreds = model.predict(pred_batches, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:23:17.287752Z","iopub.execute_input":"2022-07-05T17:23:17.288698Z","iopub.status.idle":"2022-07-05T17:23:22.632103Z","shell.execute_reply.started":"2022-07-05T17:23:17.288662Z","shell.execute_reply":"2022-07-05T17:23:22.631123Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"Threshold = 0.5\n\nfig = plt.figure(figsize =(10, 25))\ngs = gridspec.GridSpec(nrows = 8, ncols = 3)\ncolors = ['yellow','green','red']\nlabels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n\npatches = [mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\ncmap1 = mpl.colors.ListedColormap(colors[0])\ncmap2 = mpl.colors.ListedColormap(colors[1])\ncmap3 = mpl.colors.ListedColormap(colors[2])\n\nfor i in range(8):\n    images, mask = pred_batches[i]\n    sample_img = images[0, :, :, 0]\n    \n    mask1 = mask[0, :, :, 0]\n    mask2 = mask[0, :, :, 1]\n    mask3 = mask[0, :, :, 2]\n    \n    prediction_i = preds[i]\n    predict1 = prediction_i[:, :, 0]\n    predict2 = prediction_i[:, :, 1]\n    predict3 = prediction_i[:, :, 2]\n    \n    predict1 = (predict1 > Threshold).astype(np.float32)\n    predict2 = (predict2 > Threshold).astype(np.float32)\n    predict3 = (predict3 > Threshold).astype(np.float32)\n    \n    ax0 = fig.add_subplot(gs[i, 0])\n    im = ax0.imshow(sample_img, cmap='bone')\n    ax0.set_title(\"Image\", fontsize=12, y=1.01)\n    \n    ax1 = fig.add_subplot(gs[i, 1])\n    ax1.set_title(\"Mask\", fontsize=12, y=1.01)\n    l0 = ax1.imshow(sample_img, cmap=\"bone\")\n    l1 = ax1.imshow(np.ma.masked_where(mask1 == False, mask1), cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(mask2 == False, mask2), cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(mask3 == False, mask3), cmap=cmap3, alpha=1)\n    \n    ax2 = fig.add_subplot(gs[i, 2])\n    ax2.set_title(\"Predict\", fontsize=12, y=1.01)\n    l0 = ax1.imshow(sample_img, cmap=\"bone\")\n    l1 = ax1.imshow(np.ma.masked_where(predict1 == False, predict1), cmap=cmap1, alpha=1)\n    l2 = ax1.imshow(np.ma.masked_where(predict2 == False, predict2), cmap=cmap2, alpha=1)\n    l3 = ax1.imshow(np.ma.masked_where(predict3 == False, predict3), cmap=cmap3, alpha=1)\n    \n    _ = [ax.set_axis_off() for ax in [ax0, ax1, ax2]]\n    colors = [im.cmap(im.norm(1)) for im in [l1, l2, l3] ]\n    plt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4, fontsize=12, title=\"Mask Labels\", title_fontsize=12, edgecolor='black', facecolor='#c5c6c7' )\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:23:22.633991Z","iopub.execute_input":"2022-07-05T17:23:22.634353Z","iopub.status.idle":"2022-07-05T17:23:24.106398Z","shell.execute_reply.started":"2022-07-05T17:23:22.634316Z","shell.execute_reply":"2022-07-05T17:23:24.104434Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"pred_batches = DataGenerator(test_df, batch_size = BATCH_SIZE, subset=\"test\", shuffle=False)\nnum_batches = int(len(test_df)/BATCH_SIZE)\n\nfor i in range(num_batches):\n    # Predict\n    preds = model.predict(pred_batches[i],verbose=0)     # shape: (16,128,128,3)\n    \n    # Rle encode\n    for j in range(BATCH_SIZE):\n        for k in range(3):\n            pred_img = cv2.resize(preds[j,:,:,k], (test_df.loc[i*BATCH_SIZE+j,\"width\"], test_df.loc[i*BATCH_SIZE+j,\"height\"]), interpolation=cv2.INTER_NEAREST) # resize probabilities to original shape\n            pred_img = (pred_img>0.5).astype(dtype='uint8')    # classify\n            submission.loc[3*(i*BATCH_SIZE+j)+k,'predicted'] = rle_encode(pred_img)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:30:03.333905Z","iopub.execute_input":"2022-07-05T17:30:03.334546Z","iopub.status.idle":"2022-07-05T17:30:06.478921Z","shell.execute_reply.started":"2022-07-05T17:30:03.334514Z","shell.execute_reply":"2022-07-05T17:30:06.477951Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nsubmission.sample(20)","metadata":{"execution":{"iopub.status.busy":"2022-07-05T17:30:08.457593Z","iopub.execute_input":"2022-07-05T17:30:08.457985Z","iopub.status.idle":"2022-07-05T17:30:08.496246Z","shell.execute_reply.started":"2022-07-05T17:30:08.457951Z","shell.execute_reply":"2022-07-05T17:30:08.495240Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}